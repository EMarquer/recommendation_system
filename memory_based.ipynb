{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"review_id\",\"rating\",\"review_title\",'review_text','username','user_location','hotel_id','date_stayed','review_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mg/.anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "Skipping line 50647: Expected 9 fields in line 50647, saw 11. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 71068: Expected 9 fields in line 71068, saw 10. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 73612: Expected 9 fields in line 73612, saw 11. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 104136: Expected 9 fields in line 104136, saw 10. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 122095: Expected 9 fields in line 122095, saw 13. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 131883: Expected 9 fields in line 131883, saw 10. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 223766: Expected 9 fields in line 223766, saw 11. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 225005: Expected 9 fields in line 225005, saw 10. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 227448: Expected 9 fields in line 227448, saw 10. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 241246: Expected 9 fields in line 241246, saw 10. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 247661: Expected 9 fields in line 247661, saw 13. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 256300: Expected 9 fields in line 256300, saw 10. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 404206: Expected 9 fields in line 404206, saw 10. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 425331: Expected 9 fields in line 425331, saw 11. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 442308: Expected 9 fields in line 442308, saw 10. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 456868: Expected 9 fields in line 456868, saw 10. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 494247: Expected 9 fields in line 494247, saw 10. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 512290: Expected 9 fields in line 512290, saw 10. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 530081: Expected 9 fields in line 530081, saw 10. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 570492: Expected 9 fields in line 570492, saw 10. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 589162: Expected 9 fields in line 589162, saw 10. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 639489: Expected 9 fields in line 639489, saw 10. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 658224: Expected 9 fields in line 658224, saw 10. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 763312: Expected 9 fields in line 763312, saw 10. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 826830: Expected 9 fields in line 826830, saw 10. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 841518: Expected 9 fields in line 841518, saw 10. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 852016: Expected 9 fields in line 852016, saw 10. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
      "Skipping line 863930: Expected 9 fields in line 863930, saw 10. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data2.zip',sep=\";;\",error_bad_lines=False,names= names)\n",
    "df.sample(15)\n",
    "df = df.dropna(subset=['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['username'] = df['username'].fillna(\"Anon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le_user  = preprocessing.LabelEncoder()\n",
    "le_user.fit(df['username'].values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['username'] = le_user.transform(df['username'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_COUNT = len(le_user.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hotel_id'] = df['hotel_id'].fillna('UNK') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_hotel =  preprocessing.LabelEncoder()\n",
    "le_hotel.fit(df['hotel_id'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hotel_id'] = le_hotel.transform(df['hotel_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOTEL_COUNT = len(le_hotel.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score harmonization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating'] = df['rating'].fillna(-1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD,NMF,SVDpp\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import NormalPredictor\n",
    "\n",
    "\n",
    "\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "rating_df = pd.DataFrame()\n",
    "rating_df[\"rating\"] = df['rating']\n",
    "rating_df[\"username\"] = df[\"username\"]\n",
    "rating_df[\"hotel_id\"] = df[\"hotel_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(df[['username', 'hotel_id', 'rating']], reader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0581\n",
      "SVD 1.0580697005584871\n",
      "RMSE: 1.2293\n",
      "NMF 1.2292878303233175\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-8a3e3c8e9fb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malgos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.7/site-packages/surprise/prediction_algorithms/matrix_factorization.pyx\u001b[0m in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVDpp.fit\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.7/site-packages/surprise/prediction_algorithms/matrix_factorization.pyx\u001b[0m in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVDpp.sgd\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.7/site-packages/surprise/trainset.py\u001b[0m in \u001b[0;36mall_ratings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_ratings\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mu_ratings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_testset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# sample random trainset and testset\n",
    "# test set is made of 15% of the ratings.\n",
    "trainset, testset = train_test_split(data, test_size=.15)\n",
    "\n",
    "algos = [(SVD(),\"SVD\"),(NMF(),\"NMF\")]\n",
    "\n",
    "for algo,name in algos:\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    \n",
    "    print(name,accuracy.rmse(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = data.build_full_trainset()\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Than predict ratings for all pairs (u, i) that are NOT in the training set.\n",
    "testset = trainset.build_anti_testset()\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "top_n = get_top_n(predictions, n=10)\n",
    "\n",
    "# Print the recommended items for each user\n",
    "for uid, user_ratings in top_n.items():\n",
    "    print(uid, [iid for (iid, _) in user_ratings])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
